import os
import logging
from flask import Flask, request
from transformers import AutoModelForCausalLM, AutoTokenizer
from telegram import Update
from telegram.ext import ApplicationBuilder, ContextTypes, CommandHandler, MessageHandler, filters

# Telegram Token —ñ HF Token –∑ environment
TELEGRAM_TOKEN = os.environ.get("7699486025:AAGgmU_xf6mQ5UK3v9xSaVNYMWZ_8wkXEdE")
HF_TOKEN = os.environ.get("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")

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ
model_name = "bigcode/starcoder"
tokenizer = AutoTokenizer.from_pretrained(model_name, token=HF_TOKEN)
model = AutoModelForCausalLM.from_pretrained(model_name, token=HF_TOKEN)

# Flask app
app = Flask(__name__)

# Telegram bot setup
app_telegram = ApplicationBuilder().token(TELEGRAM_TOKEN).build()

# –û–±—Ä–æ–±–∫–∞ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω—å
async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_input = update.message.text
    inputs = tokenizer(user_input, return_tensors="pt")
    outputs = model.generate(**inputs, max_new_tokens=256)
    reply = tokenizer.decode(outputs[0], skip_special_tokens=True)
    await update.message.reply_text(reply)

# –ö–æ–º–∞–Ω–¥–∞ —Å—Ç–∞—Ä—Ç
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("üëã –ü—Ä–∏–≤—ñ—Ç! –Ø –±–æ—Ç –¥–ª—è –Ω–∞–ø–∏—Å–∞–Ω–Ω—è –ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏—Ö —Å–∫—Ä–∏–ø—Ç—ñ–≤.")

# –î–æ–¥–∞—î–º–æ —Ö–µ–Ω–¥–ª–µ—Ä–∏
app_telegram.add_handler(CommandHandler("start", start))
app_telegram.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

# Flask –º–∞—Ä—à—Ä—É—Ç –¥–ª—è –≤–µ–±—Ö—É–∫–∞
@app.route("/")
def home():
    return "–ë–æ—Ç –ø—Ä–∞—Ü—é—î!"

@app.route(f"/{TELEGRAM_TOKEN}", methods=["POST"])
def webhook():
    update = Update.de_json(request.get_json(force=True), app_telegram.bot)
    app_telegram.update_queue.put(update)
    return "ok"

# –ó–∞–ø—É—Å–∫ Flask
if __name__ == "__main__":
    app.run(port=10000)
